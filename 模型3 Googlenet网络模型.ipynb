{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义模型3 Googlenet",
   "id": "751d52d62f597fef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:58:13.948655Z",
     "start_time": "2024-07-24T02:58:12.177846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib qt"
   ],
   "id": "98fba72360698b24",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:58:13.952224Z",
     "start_time": "2024-07-24T02:58:13.949163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "model_accuracies = {\n",
    "    'googlenet': []\n",
    "}\n",
    "torch.cuda.empty_cache()\n",
    "# 定义批量大小\n",
    "batch_size = 60\n",
    "\n",
    "# 数据增强和预处理\n",
    "transform3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),##图像大小转化，转化为各深度学习分类器要求的图像大小\n",
    "    transforms.ToTensor(),## 将图像转换为PyTorch的张量格式，并将像素值从0-255缩放到0-1之间\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])## 标准化图像，使每个通道的像素值分布在[-1, 1]之间。\n",
    "])"
   ],
   "id": "a8939555898030ea",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:58:13.966690Z",
     "start_time": "2024-07-24T02:58:13.953760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 加载数据集\n",
    "data_dir = r'D:\\深度学习练习\\flower_photos\\flower_photos'\n",
    "train_dataset = datasets.ImageFolder(root=data_dir, transform=transform3)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "135c98e6ae25d3bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:58:13.970349Z",
     "start_time": "2024-07-24T02:58:13.966690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义Inception模块\n",
    "class Inception(nn.Module):#一个复合模块，其作用和卷积层和池化层相当\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
    "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
    "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)"
   ],
   "id": "4d1a662d591afcca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:58:13.975965Z",
     "start_time": "2024-07-24T02:58:13.971350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义GoogLeNet模型\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)#参数介绍见下\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "# self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "#192：输入特征图的通道数。这表示Inception模块接收的输入特征图具有192个通道。\n",
    "#64：1x1卷积层的输出通道数。这表示在Inception模块的第一个分支中，将通过1x1卷积层减少输入特征图的通道数，输出特征图将有64个通道。\n",
    "#96：3x3卷积层之前的1x1卷积层的输出通道数。在Inception模块的第二个分支中，首先通过一个1x1卷积层减少通道数到96个，然后再通过一个3x3卷积层。\n",
    "#128：3x3卷积层的输出通道数。在第二个分支中，3x3卷积层将输出128个通道的特征图。\n",
    "#16：5x5卷积层之前的1x1卷积层的输出通道数。在Inception模块的第三个分支中，先通过一个1x1卷积层减少通道数到16个，然后再通过一个5x5卷积层。\n",
    "#32：5x5卷积层的输出通道数。在第三个分支中，5x5卷积层将输出32个通道的特征图。\n",
    "#32：最大池化层后接1x1卷积层的输出通道数。在Inception模块的第四个分支中，先通过最大池化层进行下采样，然后通过一个1x1卷积层增加通道数到32个。   \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        #print(\"After maxpool1:\", x.size())\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.maxpool2(x)\n",
    "        #print(\"After maxpool2:\", x.size())\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        #print(\"After maxpool3:\", x.size())\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        #print(\"After maxpool4:\", x.size())\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        #print(\"After maxpool5:\", x.size())\n",
    "        x = self.avgpool(x)\n",
    "        #print(\"After avgpool:\", x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ],
   "id": "eca59bbd872d3415",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "参数检查\n",
    "from torchsummary import summary\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "##### 使用summary函数查看模型的详细信息，这里假设输入尺寸为(3, 224, 224)\n",
    "model = GoogLeNet(num_classes=5).to(device)\n",
    "summary(model, (3, 224, 224))"
   ],
   "id": "a8e9d4f4fce15250"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T03:06:34.293378Z",
     "start_time": "2024-07-24T02:58:13.975965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = GoogLeNet(num_classes=5).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 40\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "accuracy_per_epoch = []  # 存储每个epoch的准确率\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_losses.append(val_running_loss / len(val_loader))\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracy_per_epoch.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Val Loss: {val_running_loss / len(val_loader)}\")\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# 更新字典中的准确率数据\n",
    "model_accuracies['googlenet'] = accuracy_per_epoch"
   ],
   "id": "958ed14e6825a6b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Train Loss: 1.468608140297558\n",
      "Epoch 1, Val Loss: 1.2536434971767922\n",
      "Epoch 1, Validation Accuracy: 44.69%\n",
      "Epoch 2, Train Loss: 1.1769372263680333\n",
      "Epoch 2, Val Loss: 1.1258400419484014\n",
      "Epoch 2, Validation Accuracy: 48.50%\n",
      "Epoch 3, Train Loss: 1.1014044563407484\n",
      "Epoch 3, Val Loss: 1.0462428098139556\n",
      "Epoch 3, Validation Accuracy: 53.54%\n",
      "Epoch 4, Train Loss: 1.0593450276747993\n",
      "Epoch 4, Val Loss: 1.2425918319950933\n",
      "Epoch 4, Validation Accuracy: 48.23%\n",
      "Epoch 5, Train Loss: 1.0430262393277625\n",
      "Epoch 5, Val Loss: 0.9203289850898411\n",
      "Epoch 5, Validation Accuracy: 61.04%\n",
      "Epoch 6, Train Loss: 1.015951033519662\n",
      "Epoch 6, Val Loss: 0.9786207442698271\n",
      "Epoch 6, Validation Accuracy: 59.13%\n",
      "Epoch 7, Train Loss: 0.9868745499331019\n",
      "Epoch 7, Val Loss: 0.9197262473728346\n",
      "Epoch 7, Validation Accuracy: 59.95%\n",
      "Epoch 8, Train Loss: 0.9603148815424546\n",
      "Epoch 8, Val Loss: 0.983420835888904\n",
      "Epoch 8, Validation Accuracy: 57.22%\n",
      "Epoch 9, Train Loss: 0.9461500916791998\n",
      "Epoch 9, Val Loss: 0.8877328141875889\n",
      "Epoch 9, Validation Accuracy: 64.03%\n",
      "Epoch 10, Train Loss: 0.8875636034037756\n",
      "Epoch 10, Val Loss: 0.8469805639723073\n",
      "Epoch 10, Validation Accuracy: 66.62%\n",
      "Epoch 11, Train Loss: 0.8429961547903393\n",
      "Epoch 11, Val Loss: 0.8427975281425144\n",
      "Epoch 11, Validation Accuracy: 64.99%\n",
      "Epoch 12, Train Loss: 0.7896956331703974\n",
      "Epoch 12, Val Loss: 0.8034764580104662\n",
      "Epoch 12, Validation Accuracy: 67.03%\n",
      "Epoch 13, Train Loss: 0.7762083171502404\n",
      "Epoch 13, Val Loss: 0.7550782068915989\n",
      "Epoch 13, Validation Accuracy: 70.03%\n",
      "Epoch 14, Train Loss: 0.7658539171452108\n",
      "Epoch 14, Val Loss: 0.723228641178297\n",
      "Epoch 14, Validation Accuracy: 70.57%\n",
      "Epoch 15, Train Loss: 0.7183658305717551\n",
      "Epoch 15, Val Loss: 0.7275390754575315\n",
      "Epoch 15, Validation Accuracy: 72.21%\n",
      "Epoch 16, Train Loss: 0.6820187549228254\n",
      "Epoch 16, Val Loss: 0.6810870727767115\n",
      "Epoch 16, Validation Accuracy: 73.71%\n",
      "Epoch 17, Train Loss: 0.6396132934352626\n",
      "Epoch 17, Val Loss: 0.7188013792037964\n",
      "Epoch 17, Validation Accuracy: 70.98%\n",
      "Epoch 18, Train Loss: 0.6288001362396323\n",
      "Epoch 18, Val Loss: 0.6174617150555486\n",
      "Epoch 18, Validation Accuracy: 76.84%\n",
      "Epoch 19, Train Loss: 0.6003746040489363\n",
      "Epoch 19, Val Loss: 0.6179127395153046\n",
      "Epoch 19, Validation Accuracy: 75.89%\n",
      "Epoch 20, Train Loss: 0.568468294551839\n",
      "Epoch 20, Val Loss: 0.6402338976445405\n",
      "Epoch 20, Validation Accuracy: 74.52%\n",
      "Epoch 21, Train Loss: 0.5703591360994007\n",
      "Epoch 21, Val Loss: 0.6082088804763296\n",
      "Epoch 21, Validation Accuracy: 78.07%\n",
      "Epoch 22, Train Loss: 0.5158417914872584\n",
      "Epoch 22, Val Loss: 0.5962272675141044\n",
      "Epoch 22, Validation Accuracy: 78.61%\n",
      "Epoch 23, Train Loss: 0.5140477227775947\n",
      "Epoch 23, Val Loss: 0.6687808516232864\n",
      "Epoch 23, Validation Accuracy: 74.66%\n",
      "Epoch 24, Train Loss: 0.48258072737118474\n",
      "Epoch 24, Val Loss: 0.6289398540621218\n",
      "Epoch 24, Validation Accuracy: 76.29%\n",
      "Epoch 25, Train Loss: 0.424246901727241\n",
      "Epoch 25, Val Loss: 0.6820281186829442\n",
      "Epoch 25, Validation Accuracy: 75.75%\n",
      "Epoch 26, Train Loss: 0.41575082553469617\n",
      "Epoch 26, Val Loss: 0.5751031676064366\n",
      "Epoch 26, Validation Accuracy: 78.07%\n",
      "Epoch 27, Train Loss: 0.38384037626826245\n",
      "Epoch 27, Val Loss: 0.5859142593715502\n",
      "Epoch 27, Validation Accuracy: 80.52%\n",
      "Epoch 28, Train Loss: 0.36052952277595585\n",
      "Epoch 28, Val Loss: 0.6554407231185747\n",
      "Epoch 28, Validation Accuracy: 77.52%\n",
      "Epoch 29, Train Loss: 0.3997994216725878\n",
      "Epoch 29, Val Loss: 0.7938001065150552\n",
      "Epoch 29, Validation Accuracy: 76.70%\n",
      "Epoch 30, Train Loss: 0.31430356771401735\n",
      "Epoch 30, Val Loss: 0.6544477512007174\n",
      "Epoch 30, Validation Accuracy: 79.56%\n",
      "Epoch 31, Train Loss: 0.30746386297371076\n",
      "Epoch 31, Val Loss: 0.7995140202667402\n",
      "Epoch 31, Validation Accuracy: 71.53%\n",
      "Epoch 32, Train Loss: 0.310585984474291\n",
      "Epoch 32, Val Loss: 0.6951504673646844\n",
      "Epoch 32, Validation Accuracy: 79.84%\n",
      "Epoch 33, Train Loss: 0.27996999810895196\n",
      "Epoch 33, Val Loss: 0.8064856568108434\n",
      "Epoch 33, Validation Accuracy: 78.20%\n",
      "Epoch 34, Train Loss: 0.22457447891002116\n",
      "Epoch 34, Val Loss: 0.7890252470970154\n",
      "Epoch 34, Validation Accuracy: 77.38%\n",
      "Epoch 35, Train Loss: 0.21877324014254237\n",
      "Epoch 35, Val Loss: 0.7765001019705897\n",
      "Epoch 35, Validation Accuracy: 78.07%\n",
      "Epoch 36, Train Loss: 0.23138371579672978\n",
      "Epoch 36, Val Loss: 0.7493875920772552\n",
      "Epoch 36, Validation Accuracy: 78.47%\n",
      "Epoch 37, Train Loss: 0.1578055903437021\n",
      "Epoch 37, Val Loss: 0.9737874671168949\n",
      "Epoch 37, Validation Accuracy: 78.34%\n",
      "Epoch 38, Train Loss: 0.17963325527861065\n",
      "Epoch 38, Val Loss: 0.9613673894301705\n",
      "Epoch 38, Validation Accuracy: 78.34%\n",
      "Epoch 39, Train Loss: 0.17477467731046287\n",
      "Epoch 39, Val Loss: 0.9433526694774628\n",
      "Epoch 39, Validation Accuracy: 78.07%\n",
      "Epoch 40, Train Loss: 0.12095833868395699\n",
      "Epoch 40, Val Loss: 1.0102502496346184\n",
      "Epoch 40, Validation Accuracy: 79.02%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T03:06:34.542728Z",
     "start_time": "2024-07-24T03:06:34.294379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 保存模型权重\n",
    "torch.save(model.state_dict(), 'googlenet_weights.pth')\n",
    "# 保存模型结构和权重\n",
    "torch.save(model, 'googlenet_model.pth')\n",
    "accuracies_list = model_accuracies['googlenet']\n",
    "\n",
    "# 创建一个包含epoch编号和对应准确率的字典\n",
    "data = {'Epoch': list(range(1, len(accuracies_list) + 1)),\n",
    "        'Accuracy': accuracies_list}\n",
    "\n",
    "# 将字典转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 现在你可以将DataFrame保存为Excel文件\n",
    "df.to_excel('googlenet_accuracies.xlsx', index=False)\n",
    "# 清理内存\n",
    "del model\n",
    "del inputs\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "6e41b686efadc397",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:48:11.554005Z",
     "start_time": "2024-07-24T11:48:11.377502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# 实例化模型\n",
    "model = GoogLeNet(num_classes=5).to(device)\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('googlenet_weights.pth'))\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()"
   ],
   "id": "909d63b5c86295c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:49:19.760808Z",
     "start_time": "2024-07-24T11:49:16.731548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于存储预测和真实标签的列表\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 不计算梯度进行预测\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        # 将数据移动到GPU，如果可用\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测概率最高的类别\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 将预测结果和真实标签添加到列表中\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算准确率、精确率、召回率和F1分数\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}\n",
    "\n",
    "# 写入CSV文件\n",
    "with open('GoogLeNet评估.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Metric', 'Value'])\n",
    "    for metric, value in results.items():\n",
    "        writer.writerow([metric, value])\n",
    "\n",
    "print(\"Results have been saved to GoogLeNet评估.csv\")"
   ],
   "id": "5a34de687088d5bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 23/23 [00:02<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to GoogLeNet评估.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28aac20f57e3088b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
