{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型4 resnet",
   "id": "c8c43c6e38cc0e43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:33:05.006685Z",
     "start_time": "2024-07-24T06:33:03.002656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib qt"
   ],
   "id": "cd5ce9c4c5480d8f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:33:05.011337Z",
     "start_time": "2024-07-24T06:33:05.007687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "model_accuracies = {\n",
    "    'resnet': []\n",
    "}\n",
    "# 数据增强和预处理\n",
    "transform4 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 图像大小转化\n",
    "    transforms.ToTensor(),  # 将图像转换为PyTorch的张量格式，并将像素值从0-255缩放到0-1之间\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])"
   ],
   "id": "fb576c8ac9c37ecd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:33:05.024842Z",
     "start_time": "2024-07-24T06:33:05.012340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据集\n",
    "data_dir = r'D:\\深度学习练习\\flower_photos\\flower_photos'\n",
    "train_dataset = datasets.ImageFolder(root=data_dir, transform=transform4)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "63217ef2d8714a39",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:33:05.030943Z",
     "start_time": "2024-07-24T06:33:05.024842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):#残差块定义\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()# 残差路径\n",
    "        if stride != 1 or in_channels != self.expansion*out_channels:# 如果步长不为1或输入通道数与输出通道数（扩展后）不匹配，则需要改变残差路径的维度\n",
    "            self.shortcut = nn.Sequential(  # 残差路径的卷积层，用于调整通道数和进行下采样\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=5):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        # 通过添加池化层计算展平后的特征图大小\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 使特征图的尺寸变为 (1, 1)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"\n",
    "    构建一个包含多个残差块的层。\n",
    "\n",
    "    参数:\n",
    "    - block (nn.Module): 残差块的基本构建单元。\n",
    "    - out_channels (int): 残差块输出特征图的通道数。\n",
    "    - num_blocks (int): 层中残差块的数量。\n",
    "    - stride (int): 第一个残差块的卷积步长。\n",
    "\n",
    "    返回:\n",
    "    - nn.Sequential: 包含多个残差块的层。\n",
    "    \"\"\"\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        # 使用自适应池化将特征图调整为 (1, 1)\n",
    "        out = self.avgpool(out)\n",
    "        \n",
    "        # 展平特征图\n",
    "        out = torch.flatten(out, 1)  # 展平为 (batch_size, num_features)\n",
    "        \n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18(num_classes=5):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "\n",
    "\n"
   ],
   "id": "969abc7be2e40901",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:57:25.949670Z",
     "start_time": "2024-07-24T06:33:05.031945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 参数设置\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epochs = 40\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "# 创建模型实例\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "accuracies = []\n",
    "\n",
    "# 训练模型\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到GPU\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    # 将准确率存储到 model_accuracies 字典中\n",
    "    model_accuracies['resnet'].append(accuracy)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# 计算验证集的准确率\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到GPU\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n"
   ],
   "id": "361bb580c214375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Train Loss: 1.1991146537272825\n",
      "Epoch [1/40], Validation Accuracy: 57.63%\n",
      "Epoch 2, Train Loss: 0.967334267237912\n",
      "Epoch [2/40], Validation Accuracy: 64.31%\n",
      "Epoch 3, Train Loss: 0.8557030584501184\n",
      "Epoch [3/40], Validation Accuracy: 67.17%\n",
      "Epoch 4, Train Loss: 0.8060407894461051\n",
      "Epoch [4/40], Validation Accuracy: 65.94%\n",
      "Epoch 5, Train Loss: 0.7555098727993343\n",
      "Epoch [5/40], Validation Accuracy: 63.62%\n",
      "Epoch 6, Train Loss: 0.7258848062028056\n",
      "Epoch [6/40], Validation Accuracy: 65.26%\n",
      "Epoch 7, Train Loss: 0.6905408261910729\n",
      "Epoch [7/40], Validation Accuracy: 64.03%\n",
      "Epoch 8, Train Loss: 0.6345418299669805\n",
      "Epoch [8/40], Validation Accuracy: 60.08%\n",
      "Epoch 9, Train Loss: 0.612623516632163\n",
      "Epoch [9/40], Validation Accuracy: 73.43%\n",
      "Epoch 10, Train Loss: 0.5934041555485\n",
      "Epoch [10/40], Validation Accuracy: 69.75%\n",
      "Epoch 11, Train Loss: 0.5532868983952896\n",
      "Epoch [11/40], Validation Accuracy: 65.94%\n",
      "Epoch 12, Train Loss: 0.5435774122243342\n",
      "Epoch [12/40], Validation Accuracy: 72.75%\n",
      "Epoch 13, Train Loss: 0.5112020951574263\n",
      "Epoch [13/40], Validation Accuracy: 74.66%\n",
      "Epoch 14, Train Loss: 0.49758658444751863\n",
      "Epoch [14/40], Validation Accuracy: 70.44%\n",
      "Epoch 15, Train Loss: 0.5079221599127935\n",
      "Epoch [15/40], Validation Accuracy: 72.07%\n",
      "Epoch 16, Train Loss: 0.44153791957575345\n",
      "Epoch [16/40], Validation Accuracy: 75.20%\n",
      "Epoch 17, Train Loss: 0.43895732579023944\n",
      "Epoch [17/40], Validation Accuracy: 73.71%\n",
      "Epoch 18, Train Loss: 0.42273346658634103\n",
      "Epoch [18/40], Validation Accuracy: 81.06%\n",
      "Epoch 19, Train Loss: 0.3849506198388079\n",
      "Epoch [19/40], Validation Accuracy: 78.47%\n",
      "Epoch 20, Train Loss: 0.3717996913777745\n",
      "Epoch [20/40], Validation Accuracy: 63.35%\n",
      "Epoch 21, Train Loss: 0.37314997030341107\n",
      "Epoch [21/40], Validation Accuracy: 70.03%\n",
      "Epoch 22, Train Loss: 0.32515393011271954\n",
      "Epoch [22/40], Validation Accuracy: 80.93%\n",
      "Epoch 23, Train Loss: 0.3171296201484359\n",
      "Epoch [23/40], Validation Accuracy: 75.75%\n",
      "Epoch 24, Train Loss: 0.32012310899470164\n",
      "Epoch [24/40], Validation Accuracy: 74.66%\n",
      "Epoch 25, Train Loss: 0.28241783995991165\n",
      "Epoch [25/40], Validation Accuracy: 78.47%\n",
      "Epoch 26, Train Loss: 0.26787890230669925\n",
      "Epoch [26/40], Validation Accuracy: 71.93%\n",
      "Epoch 27, Train Loss: 0.24151172262171042\n",
      "Epoch [27/40], Validation Accuracy: 78.34%\n",
      "Epoch 28, Train Loss: 0.2334401360510484\n",
      "Epoch [28/40], Validation Accuracy: 68.66%\n",
      "Epoch 29, Train Loss: 0.18513083283829948\n",
      "Epoch [29/40], Validation Accuracy: 70.03%\n",
      "Epoch 30, Train Loss: 0.18718599333711292\n",
      "Epoch [30/40], Validation Accuracy: 70.30%\n",
      "Epoch 31, Train Loss: 0.16151263417028214\n",
      "Epoch [31/40], Validation Accuracy: 81.47%\n",
      "Epoch 32, Train Loss: 0.1321035612617498\n",
      "Epoch [32/40], Validation Accuracy: 71.66%\n",
      "Epoch 33, Train Loss: 0.16077553703571143\n",
      "Epoch [33/40], Validation Accuracy: 80.38%\n",
      "Epoch 34, Train Loss: 0.11879265037081811\n",
      "Epoch [34/40], Validation Accuracy: 82.15%\n",
      "Epoch 35, Train Loss: 0.10328975362379265\n",
      "Epoch [35/40], Validation Accuracy: 79.16%\n",
      "Epoch 36, Train Loss: 0.07479208714895598\n",
      "Epoch [36/40], Validation Accuracy: 79.43%\n",
      "Epoch 37, Train Loss: 0.08405585394686331\n",
      "Epoch [37/40], Validation Accuracy: 73.43%\n",
      "Epoch 38, Train Loss: 0.05350886607218696\n",
      "Epoch [38/40], Validation Accuracy: 82.29%\n",
      "Epoch 39, Train Loss: 0.04895601645314499\n",
      "Epoch [39/40], Validation Accuracy: 73.43%\n",
      "Epoch 40, Train Loss: 0.03681519272757451\n",
      "Epoch [40/40], Validation Accuracy: 74.52%\n",
      "Validation Accuracy: 74.52%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:57:26.544381Z",
     "start_time": "2024-07-24T06:57:25.950672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 保存模型权重\n",
    "torch.save(model.state_dict(), 'resnet_weights.pth')\n",
    "# 保存模型结构和权重\n",
    "torch.save(model, 'resnet_model.pth')\n",
    "accuracies_list = model_accuracies['resnet']\n",
    "\n",
    "# 创建一个包含epoch编号和对应准确率的字典\n",
    "data = {'Epoch': list(range(1, len(accuracies_list) + 1)),\n",
    "        'Accuracy': accuracies_list}\n",
    "\n",
    "# 将字典转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 现在你可以将DataFrame保存为Excel文件\n",
    "df.to_excel('resnet_accuracies.xlsx', index=False)\n",
    "# 清理内存\n",
    "del model\n",
    "del inputs\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "d4e48357ea274669",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:50:33.794017Z",
     "start_time": "2024-07-24T11:50:32.780499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# 实例化模型\n",
    "model = ResNet18(num_classes=5).to(device)\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('resnet_weights.pth'))\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()"
   ],
   "id": "c04ebc0c09012ce6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:51:16.242392Z",
     "start_time": "2024-07-24T11:51:11.650159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于存储预测和真实标签的列表\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 不计算梯度进行预测\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        # 将数据移动到GPU，如果可用\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测概率最高的类别\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 将预测结果和真实标签添加到列表中\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算准确率、精确率、召回率和F1分数\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}\n",
    "\n",
    "# 写入CSV文件\n",
    "with open('ResNet评估.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Metric', 'Value'])\n",
    "    for metric, value in results.items():\n",
    "        writer.writerow([metric, value])\n",
    "\n",
    "print(\"Results have been saved to ResNet评估.csv\")"
   ],
   "id": "b3c61e28924f5225",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 23/23 [00:04<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ResNet评估.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "640b7a65b26533c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
