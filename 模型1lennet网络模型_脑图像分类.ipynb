{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 导入必要的库函数",
   "id": "82d8a5ea1c329333"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:22:10.361842Z",
     "start_time": "2024-07-29T08:22:10.356835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib qt"
   ],
   "id": "88e966a81aec462b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:22:10.763173Z",
     "start_time": "2024-07-29T08:22:10.760267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_accuracies = {\n",
    "    'lennet_5': []\n",
    "}\n",
    "print(model_accuracies)"
   ],
   "id": "dd6a1e079fc59dcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lennet_5': []}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 深度学习模型一 lennet-5",
   "id": "ddc1272eb738b8fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.图像转化",
   "id": "4a5b352986bfdb01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:22:17.150207Z",
     "start_time": "2024-07-29T08:22:17.146697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义批量大小\n",
    "batch_size = 100\n",
    "# 数据增强和预处理\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),##图像大小转化\n",
    "    transforms.ToTensor(),## 将图像转换为PyTorch的张量格式，并将像素值从0-255缩放到0-1之间\n",
    "   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])## 标准化图像，使每个通道的像素值分布在[-1, 1]之间。这里，均值和标准差为[0.485, 0.456, 0.406]和。[0.229, 0.224, 0.225]，计算ImageNet数据集所有图像的颜色通道均值和标准差得到的。\n",
    "])"
   ],
   "id": "1a2720f2eccfdce7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.载入图片数据",
   "id": "c4a99ea35ff224d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:22:18.656490Z",
     "start_time": "2024-07-29T08:22:18.620343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据集\n",
    "data_dir = r'D:\\深度学习练习\\Brain tumor classification-20240725-1.0(1)'\n",
    "train_dataset = datasets.ImageFolder(root=data_dir, transform=transform1)#数据转化\n",
    "train_size = int(0.8 * len(train_dataset))#数据集划分，2：8划分，确定训练集大小\n",
    "val_size = len(train_dataset) - train_size#确定测试集大小\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])#随机从数据集中分配数据到测试，训练集\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)#数据分批载入训练集，每批次大小为batch_size,shuffle=True在每个epoch开始时，数据集中的样本会被随机重排\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "f8083409a3bb01c5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.定义模型1，lenet-5",
   "id": "6bbb63b894a21cdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:22:20.256798Z",
     "start_time": "2024-07-29T08:22:20.251073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义 LeNet-5 模型\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)  # 3个通道输入输出6，第一层卷积窗口大小为5，步长为2\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)#第一层池化，使用平均池化，窗口大小为2，步长为2，把卷积后的图片放小为原理的四分之一\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 调整展平后的大小\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # 输出5类\n",
    "\n",
    "    def forward(self, x):#向前传播更新\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        #print(f\"out shape1: {x.shape}\")\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #print(f\"out shape2: {x.shape}\")\n",
    "        x = self.pool2(x)\n",
    "        #print(f\"out shape3: {x.shape}\")\n",
    "        x = x.view(-1, 16 * 6 * 6)  # 确保形状匹配\n",
    "        #print(f\"out shape4: {x.shape}\")\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        #print(f\"out shape5: {x.shape}\")\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        #print(f\"out shape6: {x.shape}\")\n",
    "        x = self.fc3(x)\n",
    "        #print(f\"out shape7: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "# 参数设置\n",
    "learning_rate = 0.0001#学习效率\n",
    "epochs = 40#训练次数\n",
    "# 检查GPU是否可用，并把模型部署到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "23f7d7fad8ccd43e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.初始化训练模型1",
   "id": "493008550649885c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:24:58.048394Z",
     "start_time": "2024-07-29T08:22:21.701095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "model = LeNet5(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()#选择CrossEntropyLoss为损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)# 优化器选择为Adam\n",
    "#效果很差criterion = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "accuracies = []\n",
    "# 训练模型\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()#将模型设置为训练模式\n",
    "    running_loss = 0.0# 初始化一个变量来累积每个epoch的损失\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)#将训练数据部署到GPU上\n",
    "        optimizer.zero_grad()# 清除优化器的梯度\n",
    "        outputs = model(inputs) # 前向传播：使用模型预测输出\n",
    "        loss = criterion(outputs, labels)#计算损失\n",
    "        loss.backward()# 反向传播：计算梯度\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到GPU\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    # 将准确率存储到 model_accuracies 字典中\n",
    "    model_accuracies['lennet_5'].append(accuracy)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "# 计算验证集的准确率\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到GPU\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n"
   ],
   "id": "e3e2f82f8f4a2d1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3520895305432772\n",
      "Epoch [1/40], Validation Accuracy: 56.34%\n",
      "Epoch 2, Train Loss: 1.1349403094827084\n",
      "Epoch [2/40], Validation Accuracy: 64.89%\n",
      "Epoch 3, Train Loss: 0.9625815153121948\n",
      "Epoch [3/40], Validation Accuracy: 66.17%\n",
      "Epoch 4, Train Loss: 0.8833337227503458\n",
      "Epoch [4/40], Validation Accuracy: 66.74%\n",
      "Epoch 5, Train Loss: 0.8212433541030214\n",
      "Epoch [5/40], Validation Accuracy: 68.80%\n",
      "Epoch 6, Train Loss: 0.775716503461202\n",
      "Epoch [6/40], Validation Accuracy: 68.95%\n",
      "Epoch 7, Train Loss: 0.7365252678854424\n",
      "Epoch [7/40], Validation Accuracy: 69.16%\n",
      "Epoch 8, Train Loss: 0.7170723237489399\n",
      "Epoch [8/40], Validation Accuracy: 71.94%\n",
      "Epoch 9, Train Loss: 0.6886676183918066\n",
      "Epoch [9/40], Validation Accuracy: 70.09%\n",
      "Epoch 10, Train Loss: 0.6675241328122323\n",
      "Epoch [10/40], Validation Accuracy: 72.51%\n",
      "Epoch 11, Train Loss: 0.6403116991645411\n",
      "Epoch [11/40], Validation Accuracy: 73.22%\n",
      "Epoch 12, Train Loss: 0.633016062933102\n",
      "Epoch [12/40], Validation Accuracy: 72.65%\n",
      "Epoch 13, Train Loss: 0.624316052909483\n",
      "Epoch [13/40], Validation Accuracy: 76.50%\n",
      "Epoch 14, Train Loss: 0.6059266276526869\n",
      "Epoch [14/40], Validation Accuracy: 76.35%\n",
      "Epoch 15, Train Loss: 0.5758674385254843\n",
      "Epoch [15/40], Validation Accuracy: 78.06%\n",
      "Epoch 16, Train Loss: 0.5686756691388917\n",
      "Epoch [16/40], Validation Accuracy: 77.42%\n",
      "Epoch 17, Train Loss: 0.5505489576281163\n",
      "Epoch [17/40], Validation Accuracy: 77.07%\n",
      "Epoch 18, Train Loss: 0.5407598776775494\n",
      "Epoch [18/40], Validation Accuracy: 76.71%\n",
      "Epoch 19, Train Loss: 0.5336457124927587\n",
      "Epoch [19/40], Validation Accuracy: 77.35%\n",
      "Epoch 20, Train Loss: 0.5204006569427356\n",
      "Epoch [20/40], Validation Accuracy: 79.27%\n",
      "Epoch 21, Train Loss: 0.5134906287778888\n",
      "Epoch [21/40], Validation Accuracy: 79.27%\n",
      "Epoch 22, Train Loss: 0.5138287523336578\n",
      "Epoch [22/40], Validation Accuracy: 80.20%\n",
      "Epoch 23, Train Loss: 0.49159357579130875\n",
      "Epoch [23/40], Validation Accuracy: 80.98%\n",
      "Epoch 24, Train Loss: 0.4861198742138712\n",
      "Epoch [24/40], Validation Accuracy: 81.34%\n",
      "Epoch 25, Train Loss: 0.4775612615702445\n",
      "Epoch [25/40], Validation Accuracy: 78.99%\n",
      "Epoch 26, Train Loss: 0.4695818199400316\n",
      "Epoch [26/40], Validation Accuracy: 80.13%\n",
      "Epoch 27, Train Loss: 0.45398081969796567\n",
      "Epoch [27/40], Validation Accuracy: 80.77%\n",
      "Epoch 28, Train Loss: 0.4499200854385108\n",
      "Epoch [28/40], Validation Accuracy: 81.84%\n",
      "Epoch 29, Train Loss: 0.44232903499352305\n",
      "Epoch [29/40], Validation Accuracy: 80.91%\n",
      "Epoch 30, Train Loss: 0.4328088216614305\n",
      "Epoch [30/40], Validation Accuracy: 81.34%\n",
      "Epoch 31, Train Loss: 0.42915407502860353\n",
      "Epoch [31/40], Validation Accuracy: 82.48%\n",
      "Epoch 32, Train Loss: 0.4251240256585573\n",
      "Epoch [32/40], Validation Accuracy: 82.69%\n",
      "Epoch 33, Train Loss: 0.42367040744998996\n",
      "Epoch [33/40], Validation Accuracy: 82.05%\n",
      "Epoch 34, Train Loss: 0.4231643802241275\n",
      "Epoch [34/40], Validation Accuracy: 82.55%\n",
      "Epoch 35, Train Loss: 0.40744445904305104\n",
      "Epoch [35/40], Validation Accuracy: 83.12%\n",
      "Epoch 36, Train Loss: 0.4016207618671551\n",
      "Epoch [36/40], Validation Accuracy: 80.98%\n",
      "Epoch 37, Train Loss: 0.4074114409455082\n",
      "Epoch [37/40], Validation Accuracy: 82.83%\n",
      "Epoch 38, Train Loss: 0.3946641307128103\n",
      "Epoch [38/40], Validation Accuracy: 83.33%\n",
      "Epoch 39, Train Loss: 0.38570057692234977\n",
      "Epoch [39/40], Validation Accuracy: 83.05%\n",
      "Epoch 40, Train Loss: 0.3811889332637452\n",
      "Epoch [40/40], Validation Accuracy: 82.83%\n",
      "Validation Accuracy: 82.83%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.保存模型",
   "id": "8606b87081367746"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:26:42.976844Z",
     "start_time": "2024-07-29T08:26:42.772881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存模型权重\n",
    "torch.save(model.state_dict(), 'lenet5_brain_weights.pth')\n",
    "# 保存模型结构和权重\n",
    "torch.save(model, 'lenet5_brain_model.pth')\n",
    "accuracies_list = model_accuracies['lennet_5']\n",
    "\n",
    "# 创建一个包含epoch编号和对应准确率的字典\n",
    "data = {'Epoch': list(range(1, len(accuracies_list) + 1)),\n",
    "        'Accuracy': accuracies_list}\n",
    "\n",
    "# 将字典转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 现在你可以将DataFrame保存为Excel文件\n",
    "df.to_excel('lennet_5_brain_accuracies.xlsx', index=False)\n",
    "# 清理内存\n",
    "del model\n",
    "del inputs\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "ad66c03127741fd7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### （示例）下次调用时可加载模型",
   "id": "c23f3f7baebe4fd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:26:43.924584Z",
     "start_time": "2024-07-29T08:26:43.906255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# 实例化模型\n",
    "model = LeNet5(num_classes=4).to(device)\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('lenet5_brain_weights.pth'))\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()"
   ],
   "id": "cd7a942699724a4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ## 评估模型",
   "id": "e499185fd518b79f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T08:26:46.073550Z",
     "start_time": "2024-07-29T08:26:45.320861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于存储预测和真实标签的列表\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 不计算梯度进行预测\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        # 将数据移动到GPU，如果可用\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测概率最高的类别\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 将预测结果和真实标签添加到列表中\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算准确率、精确率、召回率和F1分数\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}\n",
    "\n",
    "# 写入CSV文件\n",
    "with open('lennet5_brain评估.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Metric', 'Value'])\n",
    "    for metric, value in results.items():\n",
    "        writer.writerow([metric, value])\n",
    "\n",
    "print(\"Results have been saved to lennet5_brain评估.csv\")"
   ],
   "id": "e233cde0f15dc8ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:00<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to lennet5_brain评估.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "86969d0e9bb6f227",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
