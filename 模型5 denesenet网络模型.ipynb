{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型5 denesenet模型",
   "id": "157b57d2b364074a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:30:35.167229Z",
     "start_time": "2024-07-24T07:30:33.224230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib qt"
   ],
   "id": "7fa3f1471b6ccd50",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:30:35.181921Z",
     "start_time": "2024-07-24T07:30:35.168230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "model_accuracies = {\n",
    "    'densenet': []\n",
    "}\n",
    "# 数据增强和预处理\n",
    "transform5 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "data_dir = r'D:\\深度学习练习\\flower_photos\\flower_photos'\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform5)\n",
    "# 划分数据集\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "c85245bd9e205cab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:30:35.188573Z",
     "start_time": "2024-07-24T07:30:35.181921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=5):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_init_features = 2 * growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_init_features, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_init_features, nblocks[0])\n",
    "        num_features = num_init_features + nblocks[0] * growth_rate\n",
    "        out_channels = int(num_features * reduction)\n",
    "        self.trans1 = Transition(num_features, out_channels)\n",
    "\n",
    "        num_features = out_channels\n",
    "        self.dense2 = self._make_dense_layers(block, num_features, nblocks[1])\n",
    "        num_features += nblocks[1] * growth_rate\n",
    "        out_channels = int(num_features * reduction)\n",
    "        self.trans2 = Transition(num_features, out_channels)\n",
    "\n",
    "        num_features = out_channels\n",
    "        self.dense3 = self._make_dense_layers(block, num_features, nblocks[2])\n",
    "        num_features += nblocks[2] * growth_rate\n",
    "        out_channels = int(num_features * reduction)\n",
    "        self.trans3 = Transition(num_features, out_channels)\n",
    "\n",
    "        num_features = out_channels\n",
    "        self.dense4 = self._make_dense_layers(block, num_features, nblocks[3])\n",
    "        num_features += nblocks[3] * growth_rate\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_features)\n",
    "        self.linear = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_channels, nblock):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_channels, self.growth_rate))\n",
    "            in_channels += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        out = F.avg_pool2d(F.relu(self.bn(out)),kernel_size=out.size()[2:])\n",
    "        #print(f\"After avg_pool2d, out shape: {out.shape}\")\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(f\"After view, out shape: {out.shape}\") \n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def DenseNet121():\n",
    "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n",
    "\n",
    "\n"
   ],
   "id": "ae3ebf83279a248f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T10:40:02.184990Z",
     "start_time": "2024-07-24T10:40:02.054148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "# 使用summary函数查看模型的详细信息，这里假设输入尺寸为(3, 224, 224)\n",
    "model_densenet = DenseNet121().to(device)\n",
    "summary(model_densenet, (3, 224, 224))"
   ],
   "id": "3e16eb0301c6c822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "            Conv2d-3        [-1, 128, 224, 224]           8,192\n",
      "       BatchNorm2d-4        [-1, 128, 224, 224]             256\n",
      "            Conv2d-5         [-1, 32, 224, 224]          36,864\n",
      "        Bottleneck-6         [-1, 96, 224, 224]               0\n",
      "       BatchNorm2d-7         [-1, 96, 224, 224]             192\n",
      "            Conv2d-8        [-1, 128, 224, 224]          12,288\n",
      "       BatchNorm2d-9        [-1, 128, 224, 224]             256\n",
      "           Conv2d-10         [-1, 32, 224, 224]          36,864\n",
      "       Bottleneck-11        [-1, 128, 224, 224]               0\n",
      "      BatchNorm2d-12        [-1, 128, 224, 224]             256\n",
      "           Conv2d-13        [-1, 128, 224, 224]          16,384\n",
      "      BatchNorm2d-14        [-1, 128, 224, 224]             256\n",
      "           Conv2d-15         [-1, 32, 224, 224]          36,864\n",
      "       Bottleneck-16        [-1, 160, 224, 224]               0\n",
      "      BatchNorm2d-17        [-1, 160, 224, 224]             320\n",
      "           Conv2d-18        [-1, 128, 224, 224]          20,480\n",
      "      BatchNorm2d-19        [-1, 128, 224, 224]             256\n",
      "           Conv2d-20         [-1, 32, 224, 224]          36,864\n",
      "       Bottleneck-21        [-1, 192, 224, 224]               0\n",
      "      BatchNorm2d-22        [-1, 192, 224, 224]             384\n",
      "           Conv2d-23        [-1, 128, 224, 224]          24,576\n",
      "      BatchNorm2d-24        [-1, 128, 224, 224]             256\n",
      "           Conv2d-25         [-1, 32, 224, 224]          36,864\n",
      "       Bottleneck-26        [-1, 224, 224, 224]               0\n",
      "      BatchNorm2d-27        [-1, 224, 224, 224]             448\n",
      "           Conv2d-28        [-1, 128, 224, 224]          28,672\n",
      "      BatchNorm2d-29        [-1, 128, 224, 224]             256\n",
      "           Conv2d-30         [-1, 32, 224, 224]          36,864\n",
      "       Bottleneck-31        [-1, 256, 224, 224]               0\n",
      "      BatchNorm2d-32        [-1, 256, 224, 224]             512\n",
      "           Conv2d-33        [-1, 128, 224, 224]          32,768\n",
      "       Transition-34        [-1, 128, 112, 112]               0\n",
      "      BatchNorm2d-35        [-1, 128, 112, 112]             256\n",
      "           Conv2d-36        [-1, 128, 112, 112]          16,384\n",
      "      BatchNorm2d-37        [-1, 128, 112, 112]             256\n",
      "           Conv2d-38         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-39        [-1, 160, 112, 112]               0\n",
      "      BatchNorm2d-40        [-1, 160, 112, 112]             320\n",
      "           Conv2d-41        [-1, 128, 112, 112]          20,480\n",
      "      BatchNorm2d-42        [-1, 128, 112, 112]             256\n",
      "           Conv2d-43         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-44        [-1, 192, 112, 112]               0\n",
      "      BatchNorm2d-45        [-1, 192, 112, 112]             384\n",
      "           Conv2d-46        [-1, 128, 112, 112]          24,576\n",
      "      BatchNorm2d-47        [-1, 128, 112, 112]             256\n",
      "           Conv2d-48         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-49        [-1, 224, 112, 112]               0\n",
      "      BatchNorm2d-50        [-1, 224, 112, 112]             448\n",
      "           Conv2d-51        [-1, 128, 112, 112]          28,672\n",
      "      BatchNorm2d-52        [-1, 128, 112, 112]             256\n",
      "           Conv2d-53         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-54        [-1, 256, 112, 112]               0\n",
      "      BatchNorm2d-55        [-1, 256, 112, 112]             512\n",
      "           Conv2d-56        [-1, 128, 112, 112]          32,768\n",
      "      BatchNorm2d-57        [-1, 128, 112, 112]             256\n",
      "           Conv2d-58         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-59        [-1, 288, 112, 112]               0\n",
      "      BatchNorm2d-60        [-1, 288, 112, 112]             576\n",
      "           Conv2d-61        [-1, 128, 112, 112]          36,864\n",
      "      BatchNorm2d-62        [-1, 128, 112, 112]             256\n",
      "           Conv2d-63         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-64        [-1, 320, 112, 112]               0\n",
      "      BatchNorm2d-65        [-1, 320, 112, 112]             640\n",
      "           Conv2d-66        [-1, 128, 112, 112]          40,960\n",
      "      BatchNorm2d-67        [-1, 128, 112, 112]             256\n",
      "           Conv2d-68         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-69        [-1, 352, 112, 112]               0\n",
      "      BatchNorm2d-70        [-1, 352, 112, 112]             704\n",
      "           Conv2d-71        [-1, 128, 112, 112]          45,056\n",
      "      BatchNorm2d-72        [-1, 128, 112, 112]             256\n",
      "           Conv2d-73         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-74        [-1, 384, 112, 112]               0\n",
      "      BatchNorm2d-75        [-1, 384, 112, 112]             768\n",
      "           Conv2d-76        [-1, 128, 112, 112]          49,152\n",
      "      BatchNorm2d-77        [-1, 128, 112, 112]             256\n",
      "           Conv2d-78         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-79        [-1, 416, 112, 112]               0\n",
      "      BatchNorm2d-80        [-1, 416, 112, 112]             832\n",
      "           Conv2d-81        [-1, 128, 112, 112]          53,248\n",
      "      BatchNorm2d-82        [-1, 128, 112, 112]             256\n",
      "           Conv2d-83         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-84        [-1, 448, 112, 112]               0\n",
      "      BatchNorm2d-85        [-1, 448, 112, 112]             896\n",
      "           Conv2d-86        [-1, 128, 112, 112]          57,344\n",
      "      BatchNorm2d-87        [-1, 128, 112, 112]             256\n",
      "           Conv2d-88         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-89        [-1, 480, 112, 112]               0\n",
      "      BatchNorm2d-90        [-1, 480, 112, 112]             960\n",
      "           Conv2d-91        [-1, 128, 112, 112]          61,440\n",
      "      BatchNorm2d-92        [-1, 128, 112, 112]             256\n",
      "           Conv2d-93         [-1, 32, 112, 112]          36,864\n",
      "       Bottleneck-94        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-95        [-1, 512, 112, 112]           1,024\n",
      "           Conv2d-96        [-1, 256, 112, 112]         131,072\n",
      "       Transition-97          [-1, 256, 56, 56]               0\n",
      "      BatchNorm2d-98          [-1, 256, 56, 56]             512\n",
      "           Conv2d-99          [-1, 128, 56, 56]          32,768\n",
      "     BatchNorm2d-100          [-1, 128, 56, 56]             256\n",
      "          Conv2d-101           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-102          [-1, 288, 56, 56]               0\n",
      "     BatchNorm2d-103          [-1, 288, 56, 56]             576\n",
      "          Conv2d-104          [-1, 128, 56, 56]          36,864\n",
      "     BatchNorm2d-105          [-1, 128, 56, 56]             256\n",
      "          Conv2d-106           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-107          [-1, 320, 56, 56]               0\n",
      "     BatchNorm2d-108          [-1, 320, 56, 56]             640\n",
      "          Conv2d-109          [-1, 128, 56, 56]          40,960\n",
      "     BatchNorm2d-110          [-1, 128, 56, 56]             256\n",
      "          Conv2d-111           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-112          [-1, 352, 56, 56]               0\n",
      "     BatchNorm2d-113          [-1, 352, 56, 56]             704\n",
      "          Conv2d-114          [-1, 128, 56, 56]          45,056\n",
      "     BatchNorm2d-115          [-1, 128, 56, 56]             256\n",
      "          Conv2d-116           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-117          [-1, 384, 56, 56]               0\n",
      "     BatchNorm2d-118          [-1, 384, 56, 56]             768\n",
      "          Conv2d-119          [-1, 128, 56, 56]          49,152\n",
      "     BatchNorm2d-120          [-1, 128, 56, 56]             256\n",
      "          Conv2d-121           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-122          [-1, 416, 56, 56]               0\n",
      "     BatchNorm2d-123          [-1, 416, 56, 56]             832\n",
      "          Conv2d-124          [-1, 128, 56, 56]          53,248\n",
      "     BatchNorm2d-125          [-1, 128, 56, 56]             256\n",
      "          Conv2d-126           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-127          [-1, 448, 56, 56]               0\n",
      "     BatchNorm2d-128          [-1, 448, 56, 56]             896\n",
      "          Conv2d-129          [-1, 128, 56, 56]          57,344\n",
      "     BatchNorm2d-130          [-1, 128, 56, 56]             256\n",
      "          Conv2d-131           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-132          [-1, 480, 56, 56]               0\n",
      "     BatchNorm2d-133          [-1, 480, 56, 56]             960\n",
      "          Conv2d-134          [-1, 128, 56, 56]          61,440\n",
      "     BatchNorm2d-135          [-1, 128, 56, 56]             256\n",
      "          Conv2d-136           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-137          [-1, 512, 56, 56]               0\n",
      "     BatchNorm2d-138          [-1, 512, 56, 56]           1,024\n",
      "          Conv2d-139          [-1, 128, 56, 56]          65,536\n",
      "     BatchNorm2d-140          [-1, 128, 56, 56]             256\n",
      "          Conv2d-141           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-142          [-1, 544, 56, 56]               0\n",
      "     BatchNorm2d-143          [-1, 544, 56, 56]           1,088\n",
      "          Conv2d-144          [-1, 128, 56, 56]          69,632\n",
      "     BatchNorm2d-145          [-1, 128, 56, 56]             256\n",
      "          Conv2d-146           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-147          [-1, 576, 56, 56]               0\n",
      "     BatchNorm2d-148          [-1, 576, 56, 56]           1,152\n",
      "          Conv2d-149          [-1, 128, 56, 56]          73,728\n",
      "     BatchNorm2d-150          [-1, 128, 56, 56]             256\n",
      "          Conv2d-151           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-152          [-1, 608, 56, 56]               0\n",
      "     BatchNorm2d-153          [-1, 608, 56, 56]           1,216\n",
      "          Conv2d-154          [-1, 128, 56, 56]          77,824\n",
      "     BatchNorm2d-155          [-1, 128, 56, 56]             256\n",
      "          Conv2d-156           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-157          [-1, 640, 56, 56]               0\n",
      "     BatchNorm2d-158          [-1, 640, 56, 56]           1,280\n",
      "          Conv2d-159          [-1, 128, 56, 56]          81,920\n",
      "     BatchNorm2d-160          [-1, 128, 56, 56]             256\n",
      "          Conv2d-161           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-162          [-1, 672, 56, 56]               0\n",
      "     BatchNorm2d-163          [-1, 672, 56, 56]           1,344\n",
      "          Conv2d-164          [-1, 128, 56, 56]          86,016\n",
      "     BatchNorm2d-165          [-1, 128, 56, 56]             256\n",
      "          Conv2d-166           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-167          [-1, 704, 56, 56]               0\n",
      "     BatchNorm2d-168          [-1, 704, 56, 56]           1,408\n",
      "          Conv2d-169          [-1, 128, 56, 56]          90,112\n",
      "     BatchNorm2d-170          [-1, 128, 56, 56]             256\n",
      "          Conv2d-171           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-172          [-1, 736, 56, 56]               0\n",
      "     BatchNorm2d-173          [-1, 736, 56, 56]           1,472\n",
      "          Conv2d-174          [-1, 128, 56, 56]          94,208\n",
      "     BatchNorm2d-175          [-1, 128, 56, 56]             256\n",
      "          Conv2d-176           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-177          [-1, 768, 56, 56]               0\n",
      "     BatchNorm2d-178          [-1, 768, 56, 56]           1,536\n",
      "          Conv2d-179          [-1, 128, 56, 56]          98,304\n",
      "     BatchNorm2d-180          [-1, 128, 56, 56]             256\n",
      "          Conv2d-181           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-182          [-1, 800, 56, 56]               0\n",
      "     BatchNorm2d-183          [-1, 800, 56, 56]           1,600\n",
      "          Conv2d-184          [-1, 128, 56, 56]         102,400\n",
      "     BatchNorm2d-185          [-1, 128, 56, 56]             256\n",
      "          Conv2d-186           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-187          [-1, 832, 56, 56]               0\n",
      "     BatchNorm2d-188          [-1, 832, 56, 56]           1,664\n",
      "          Conv2d-189          [-1, 128, 56, 56]         106,496\n",
      "     BatchNorm2d-190          [-1, 128, 56, 56]             256\n",
      "          Conv2d-191           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-192          [-1, 864, 56, 56]               0\n",
      "     BatchNorm2d-193          [-1, 864, 56, 56]           1,728\n",
      "          Conv2d-194          [-1, 128, 56, 56]         110,592\n",
      "     BatchNorm2d-195          [-1, 128, 56, 56]             256\n",
      "          Conv2d-196           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-197          [-1, 896, 56, 56]               0\n",
      "     BatchNorm2d-198          [-1, 896, 56, 56]           1,792\n",
      "          Conv2d-199          [-1, 128, 56, 56]         114,688\n",
      "     BatchNorm2d-200          [-1, 128, 56, 56]             256\n",
      "          Conv2d-201           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-202          [-1, 928, 56, 56]               0\n",
      "     BatchNorm2d-203          [-1, 928, 56, 56]           1,856\n",
      "          Conv2d-204          [-1, 128, 56, 56]         118,784\n",
      "     BatchNorm2d-205          [-1, 128, 56, 56]             256\n",
      "          Conv2d-206           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-207          [-1, 960, 56, 56]               0\n",
      "     BatchNorm2d-208          [-1, 960, 56, 56]           1,920\n",
      "          Conv2d-209          [-1, 128, 56, 56]         122,880\n",
      "     BatchNorm2d-210          [-1, 128, 56, 56]             256\n",
      "          Conv2d-211           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-212          [-1, 992, 56, 56]               0\n",
      "     BatchNorm2d-213          [-1, 992, 56, 56]           1,984\n",
      "          Conv2d-214          [-1, 128, 56, 56]         126,976\n",
      "     BatchNorm2d-215          [-1, 128, 56, 56]             256\n",
      "          Conv2d-216           [-1, 32, 56, 56]          36,864\n",
      "      Bottleneck-217         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-218         [-1, 1024, 56, 56]           2,048\n",
      "          Conv2d-219          [-1, 512, 56, 56]         524,288\n",
      "      Transition-220          [-1, 512, 28, 28]               0\n",
      "     BatchNorm2d-221          [-1, 512, 28, 28]           1,024\n",
      "          Conv2d-222          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-223          [-1, 128, 28, 28]             256\n",
      "          Conv2d-224           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-225          [-1, 544, 28, 28]               0\n",
      "     BatchNorm2d-226          [-1, 544, 28, 28]           1,088\n",
      "          Conv2d-227          [-1, 128, 28, 28]          69,632\n",
      "     BatchNorm2d-228          [-1, 128, 28, 28]             256\n",
      "          Conv2d-229           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-230          [-1, 576, 28, 28]               0\n",
      "     BatchNorm2d-231          [-1, 576, 28, 28]           1,152\n",
      "          Conv2d-232          [-1, 128, 28, 28]          73,728\n",
      "     BatchNorm2d-233          [-1, 128, 28, 28]             256\n",
      "          Conv2d-234           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-235          [-1, 608, 28, 28]               0\n",
      "     BatchNorm2d-236          [-1, 608, 28, 28]           1,216\n",
      "          Conv2d-237          [-1, 128, 28, 28]          77,824\n",
      "     BatchNorm2d-238          [-1, 128, 28, 28]             256\n",
      "          Conv2d-239           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-240          [-1, 640, 28, 28]               0\n",
      "     BatchNorm2d-241          [-1, 640, 28, 28]           1,280\n",
      "          Conv2d-242          [-1, 128, 28, 28]          81,920\n",
      "     BatchNorm2d-243          [-1, 128, 28, 28]             256\n",
      "          Conv2d-244           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-245          [-1, 672, 28, 28]               0\n",
      "     BatchNorm2d-246          [-1, 672, 28, 28]           1,344\n",
      "          Conv2d-247          [-1, 128, 28, 28]          86,016\n",
      "     BatchNorm2d-248          [-1, 128, 28, 28]             256\n",
      "          Conv2d-249           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-250          [-1, 704, 28, 28]               0\n",
      "     BatchNorm2d-251          [-1, 704, 28, 28]           1,408\n",
      "          Conv2d-252          [-1, 128, 28, 28]          90,112\n",
      "     BatchNorm2d-253          [-1, 128, 28, 28]             256\n",
      "          Conv2d-254           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-255          [-1, 736, 28, 28]               0\n",
      "     BatchNorm2d-256          [-1, 736, 28, 28]           1,472\n",
      "          Conv2d-257          [-1, 128, 28, 28]          94,208\n",
      "     BatchNorm2d-258          [-1, 128, 28, 28]             256\n",
      "          Conv2d-259           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-260          [-1, 768, 28, 28]               0\n",
      "     BatchNorm2d-261          [-1, 768, 28, 28]           1,536\n",
      "          Conv2d-262          [-1, 128, 28, 28]          98,304\n",
      "     BatchNorm2d-263          [-1, 128, 28, 28]             256\n",
      "          Conv2d-264           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-265          [-1, 800, 28, 28]               0\n",
      "     BatchNorm2d-266          [-1, 800, 28, 28]           1,600\n",
      "          Conv2d-267          [-1, 128, 28, 28]         102,400\n",
      "     BatchNorm2d-268          [-1, 128, 28, 28]             256\n",
      "          Conv2d-269           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-270          [-1, 832, 28, 28]               0\n",
      "     BatchNorm2d-271          [-1, 832, 28, 28]           1,664\n",
      "          Conv2d-272          [-1, 128, 28, 28]         106,496\n",
      "     BatchNorm2d-273          [-1, 128, 28, 28]             256\n",
      "          Conv2d-274           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-275          [-1, 864, 28, 28]               0\n",
      "     BatchNorm2d-276          [-1, 864, 28, 28]           1,728\n",
      "          Conv2d-277          [-1, 128, 28, 28]         110,592\n",
      "     BatchNorm2d-278          [-1, 128, 28, 28]             256\n",
      "          Conv2d-279           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-280          [-1, 896, 28, 28]               0\n",
      "     BatchNorm2d-281          [-1, 896, 28, 28]           1,792\n",
      "          Conv2d-282          [-1, 128, 28, 28]         114,688\n",
      "     BatchNorm2d-283          [-1, 128, 28, 28]             256\n",
      "          Conv2d-284           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-285          [-1, 928, 28, 28]               0\n",
      "     BatchNorm2d-286          [-1, 928, 28, 28]           1,856\n",
      "          Conv2d-287          [-1, 128, 28, 28]         118,784\n",
      "     BatchNorm2d-288          [-1, 128, 28, 28]             256\n",
      "          Conv2d-289           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-290          [-1, 960, 28, 28]               0\n",
      "     BatchNorm2d-291          [-1, 960, 28, 28]           1,920\n",
      "          Conv2d-292          [-1, 128, 28, 28]         122,880\n",
      "     BatchNorm2d-293          [-1, 128, 28, 28]             256\n",
      "          Conv2d-294           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-295          [-1, 992, 28, 28]               0\n",
      "     BatchNorm2d-296          [-1, 992, 28, 28]           1,984\n",
      "          Conv2d-297          [-1, 128, 28, 28]         126,976\n",
      "     BatchNorm2d-298          [-1, 128, 28, 28]             256\n",
      "          Conv2d-299           [-1, 32, 28, 28]          36,864\n",
      "      Bottleneck-300         [-1, 1024, 28, 28]               0\n",
      "     BatchNorm2d-301         [-1, 1024, 28, 28]           2,048\n",
      "          Linear-302                    [-1, 5]           5,125\n",
      "================================================================\n",
      "Total params: 6,951,173\n",
      "Trainable params: 6,951,173\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3846.50\n",
      "Params size (MB): 26.52\n",
      "Estimated Total Size (MB): 3873.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:52:38.976277Z",
     "start_time": "2024-07-24T07:30:35.189574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建模型实例\n",
    "model_densenet = DenseNet121()\n",
    "model_densenet = model_densenet.to(device)\n",
    "\n",
    "# 设置损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_densenet.parameters(), lr=0.0001)\n",
    "\n",
    "# 训练模型\n",
    "model_densenet.train()\n",
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    # 在验证集上评估模型\n",
    "    model_densenet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_densenet(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # 将准确率存储到 model_accuracies 字典中\n",
    "    model_accuracies['densenet'].append(accuracy)\n",
    "\n",
    "    # 重新设定模型为训练模式\n",
    "    model_densenet.train()"
   ],
   "id": "a8adbe57bd899abb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.2361697893969867\n",
      "Epoch [1/40], Validation Accuracy: 61.31%\n",
      "Epoch 2, Train Loss: 1.0899356583551485\n",
      "Epoch [2/40], Validation Accuracy: 62.67%\n",
      "Epoch 3, Train Loss: 1.0241139536001245\n",
      "Epoch [3/40], Validation Accuracy: 65.67%\n",
      "Epoch 4, Train Loss: 0.9983480230886109\n",
      "Epoch [4/40], Validation Accuracy: 62.53%\n",
      "Epoch 5, Train Loss: 0.9529011021767344\n",
      "Epoch [5/40], Validation Accuracy: 67.30%\n",
      "Epoch 6, Train Loss: 0.9017110862902232\n",
      "Epoch [6/40], Validation Accuracy: 70.71%\n",
      "Epoch 7, Train Loss: 0.8920011225403571\n",
      "Epoch [7/40], Validation Accuracy: 72.34%\n",
      "Epoch 8, Train Loss: 0.8507806403296334\n",
      "Epoch [8/40], Validation Accuracy: 74.25%\n",
      "Epoch 9, Train Loss: 0.7992302098140425\n",
      "Epoch [9/40], Validation Accuracy: 75.89%\n",
      "Epoch 10, Train Loss: 0.7562685747079704\n",
      "Epoch [10/40], Validation Accuracy: 71.66%\n",
      "Epoch 11, Train Loss: 0.749924975618416\n",
      "Epoch [11/40], Validation Accuracy: 69.07%\n",
      "Epoch 12, Train Loss: 0.727568082739504\n",
      "Epoch [12/40], Validation Accuracy: 73.16%\n",
      "Epoch 13, Train Loss: 0.6983540808515889\n",
      "Epoch [13/40], Validation Accuracy: 76.57%\n",
      "Epoch 14, Train Loss: 0.7009986352707659\n",
      "Epoch [14/40], Validation Accuracy: 77.66%\n",
      "Epoch 15, Train Loss: 0.6405751354764311\n",
      "Epoch [15/40], Validation Accuracy: 78.61%\n",
      "Epoch 16, Train Loss: 0.6382914319026227\n",
      "Epoch [16/40], Validation Accuracy: 76.29%\n",
      "Epoch 17, Train Loss: 0.6258958027983198\n",
      "Epoch [17/40], Validation Accuracy: 79.97%\n",
      "Epoch 18, Train Loss: 0.6015870547568312\n",
      "Epoch [18/40], Validation Accuracy: 76.70%\n",
      "Epoch 19, Train Loss: 0.595951947737105\n",
      "Epoch [19/40], Validation Accuracy: 80.11%\n",
      "Epoch 20, Train Loss: 0.5861269432519164\n",
      "Epoch [20/40], Validation Accuracy: 81.47%\n",
      "Epoch 21, Train Loss: 0.5626101459243468\n",
      "Epoch [21/40], Validation Accuracy: 76.02%\n",
      "Epoch 22, Train Loss: 0.5590543911773331\n",
      "Epoch [22/40], Validation Accuracy: 80.79%\n",
      "Epoch 23, Train Loss: 0.5543849417103492\n",
      "Epoch [23/40], Validation Accuracy: 80.25%\n",
      "Epoch 24, Train Loss: 0.5363997892989796\n",
      "Epoch [24/40], Validation Accuracy: 78.88%\n",
      "Epoch 25, Train Loss: 0.5251887337209619\n",
      "Epoch [25/40], Validation Accuracy: 80.38%\n",
      "Epoch 26, Train Loss: 0.5002813635203911\n",
      "Epoch [26/40], Validation Accuracy: 79.84%\n",
      "Epoch 27, Train Loss: 0.4767469677770016\n",
      "Epoch [27/40], Validation Accuracy: 80.25%\n",
      "Epoch 28, Train Loss: 0.4822764173264102\n",
      "Epoch [28/40], Validation Accuracy: 81.88%\n",
      "Epoch 29, Train Loss: 0.46234111441489384\n",
      "Epoch [29/40], Validation Accuracy: 80.79%\n",
      "Epoch 30, Train Loss: 0.46951203767818456\n",
      "Epoch [30/40], Validation Accuracy: 82.56%\n",
      "Epoch 31, Train Loss: 0.4514277599599897\n",
      "Epoch [31/40], Validation Accuracy: 86.38%\n",
      "Epoch 32, Train Loss: 0.4364513200308595\n",
      "Epoch [32/40], Validation Accuracy: 83.65%\n",
      "Epoch 33, Train Loss: 0.4233274345229171\n",
      "Epoch [33/40], Validation Accuracy: 84.20%\n",
      "Epoch 34, Train Loss: 0.42930235399351435\n",
      "Epoch [34/40], Validation Accuracy: 82.97%\n",
      "Epoch 35, Train Loss: 0.4134234023546534\n",
      "Epoch [35/40], Validation Accuracy: 81.20%\n",
      "Epoch 36, Train Loss: 0.4212791195405381\n",
      "Epoch [36/40], Validation Accuracy: 81.47%\n",
      "Epoch 37, Train Loss: 0.40368846189610813\n",
      "Epoch [37/40], Validation Accuracy: 84.33%\n",
      "Epoch 38, Train Loss: 0.3818887150333244\n",
      "Epoch [38/40], Validation Accuracy: 82.70%\n",
      "Epoch 39, Train Loss: 0.39739382791009786\n",
      "Epoch [39/40], Validation Accuracy: 80.65%\n",
      "Epoch 40, Train Loss: 0.3726152337878486\n",
      "Epoch [40/40], Validation Accuracy: 83.65%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:52:39.333545Z",
     "start_time": "2024-07-24T08:52:38.978279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存模型权重\n",
    "torch.save(model_densenet.state_dict(), 'densenet_weights.pth')\n",
    "# 保存模型结构和权重\n",
    "torch.save(model_densenet, 'densenet_model.pth')\n",
    "accuracies_list = model_accuracies['densenet']\n",
    "\n",
    "# 创建一个包含epoch编号和对应准确率的字典\n",
    "data = {'Epoch': list(range(1, len(accuracies_list) + 1)),\n",
    "        'Accuracy': accuracies_list}\n",
    "\n",
    "# 将字典转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 现在你可以将DataFrame保存为Excel文件\n",
    "df.to_excel('densenet_accuracies.xlsx', index=False)\n",
    "# 清理内存\n",
    "del model_densenet\n",
    "del inputs\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "f62cf49a5fd69455",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:52:57.236648Z",
     "start_time": "2024-07-24T11:52:56.981014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# 实例化模型\n",
    "model = DenseNet121() .to(device)\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('densenet_weights.pth'))\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()"
   ],
   "id": "d16ff8b65227a988",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition(\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition(\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition(\n",
       "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=1024, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T11:53:43.525635Z",
     "start_time": "2024-07-24T11:53:30.864782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于存储预测和真实标签的列表\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 不计算梯度进行预测\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        # 将数据移动到GPU，如果可用\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测概率最高的类别\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 将预测结果和真实标签添加到列表中\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算准确率、精确率、召回率和F1分数\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}\n",
    "\n",
    "# 写入CSV文件\n",
    "with open('DenseNet评估.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Metric', 'Value'])\n",
    "    for metric, value in results.items():\n",
    "        writer.writerow([metric, value])\n",
    "\n",
    "print(\"Results have been saved to DenseNet评估.csv\")"
   ],
   "id": "50819e780ca15c3d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:12<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to DenseNet评估.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6171b8aa1a083"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
